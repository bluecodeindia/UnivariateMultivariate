{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Conv_LSTM.ipynb","private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPWEwAfhsR9bwX6j0WB8GBX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"S8mrjP_qFaS7"},"source":["import math\n","import os\n","import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot\n","from random import shuffle\n","from sklearn.metrics import mean_squared_error\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers import RepeatVector\n","from keras.layers import TimeDistributed\n","from keras.models import model_from_json\n","from keras.layers import Bidirectional\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv1D\n","from keras.layers.convolutional import MaxPooling1D\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","from sklearn import preprocessing\n","%matplotlib inline\n","from keras.layers import ConvLSTM2D"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pLKiAUtFjnS"},"source":["import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XfcfPvdCFlsr"},"source":["plt.style.use('ggplot')\n","plt.rcParams['figure.figsize'] = (10, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K8CEQN2QFoc3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3_s0nsr-FzHk"},"source":["File=\"/content/drive/My Drive/Tangni\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U5nmGdmSF78G"},"source":["data=pd.read_csv(File + '/weekly_angle.csv',header=0, usecols=[0, 1, 2, 3, 4, 5], index_col=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xeNclmg3F-g8"},"source":["min_max_scaler = preprocessing.MinMaxScaler()\n","x_scaled = min_max_scaler.fit_transform(data)\n","df_normalized = pd.DataFrame(x_scaled)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZPz2nPZGBDk"},"source":["BH1=np.array(df_normalized[0])\n","BH2=np.array(df_normalized[1])\n","BH3=np.array(df_normalized[2])\n","BH4=np.array(df_normalized[3])\n","BH5=np.array(df_normalized[4])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"huY2MSmwGIj0"},"source":["plt.plot(BH5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rEuETRxbGLMs"},"source":["def rmse(predictions, targets):\n","    return np.sqrt(np.mean((predictions-targets)**2,axis=0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DyJeGJLfGO26"},"source":["def fit_model(X, y, n_timesteps, n_features,node,epochs):\n","\n","  model=Sequential()\n","\n","\n","\n","  model.add(ConvLSTM2D(filters=node, kernel_size=(1, 2), activation='relu', input_shape=(None,1, n_timesteps,n_features)))\n","  model.add(Flatten())\n","  model.add(Dense(n_features))\n","\n","\n","  print(X.shape)\n","  print(X)\n","  model.compile(optimizer='adam',loss='mse')\n","  model.fit(X,y, epochs,verbose=0)\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yzKH9igyGepz"},"source":["# split a multivariate sequence into samples\n","def split_sequences(sequences, n_steps_in, n_steps_out):\n","  X, y = list(), list()\n","  for i in range(len(sequences)):\n","    # find the end of this pattern\n","    end_ix = i + n_steps_in\n","    out_end_ix = end_ix + n_steps_out\n","    # check if we are beyond the dataset\n","    if out_end_ix > len(sequences):\n","      break\n","    # gather input and output parts of the pattern\n","    seq_x, seq_y = sequences[i:end_ix], sequences[end_ix:out_end_ix]\n","    X.append(seq_x)\n","    y.append(seq_y)\n","  return np.array(X), np.array(y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0A1_J8raGRUu"},"source":["def time_series(BH1, BH2, BH3, BH4, BH5, n_steps, n_features):\n","\n","  Train_BH1, Test_BH1=BH1[:62], BH1[62:]\n","  Train_BH2, Test_BH2=BH2[:62], BH2[62:]\n","  Train_BH3, Test_BH3=BH3[:62], BH3[62:]\n","  Train_BH4, Test_BH4=BH4[:62], BH4[62:]\n","  Train_BH5, Test_BH5=BH5[:62], BH5[62:]\n","\n","  in_seq1 = Train_BH1.reshape((len(Train_BH1), 1))\n","  in_seq2 = Train_BH2.reshape((len(Train_BH2), 1))\n","  in_seq3 = Train_BH3.reshape((len(Train_BH3), 1))\n","  in_seq4 = Train_BH4.reshape((len(Train_BH4), 1))\n","  in_seq5 = Train_BH5.reshape((len(Train_BH5), 1))\n","  test_seq1 = Test_BH1.reshape((len(Test_BH1), 1))\n","  test_seq2 = Test_BH2.reshape((len(Test_BH2), 1))\n","  test_seq3 = Test_BH3.reshape((len(Test_BH3), 1))\n","  test_seq4 = Test_BH4.reshape((len(Test_BH4), 1))\n","  test_seq5 = Test_BH5.reshape((len(Test_BH5), 1))\n","\n","\n","  # horizontally stack columns\n","  dataset = np.hstack((in_seq1, in_seq2, in_seq3, in_seq4, in_seq5))\n","  test_dataset = np.hstack((test_seq1, test_seq2, test_seq3, test_seq4, test_seq5))\n","  # print(dataset)\n","\n","  # convert into input/output\n","  X, y = split_sequences(dataset, n_steps,1)\n","  test_X, test_y = split_sequences(test_dataset, n_steps,1)\n","\n","  \n","\n","  return X, y, test_X, test_y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qwlYBediIuyy"},"source":["def model(n_steps,node,epochs):\n","\n","  n_features=5\n","  total_error=[]\n","\n","\n","  train_E=[]\n","  test_E=[] \n","\n","\n","\n","  \n","  X, y, test_X, test_y=time_series(BH1, BH2, BH3, BH4, BH5, n_steps, n_features, )\n","  X = X.reshape((X.shape[0], 1, 1, n_steps, n_features))\n","  test_X = test_X.reshape((test_X.shape[0], 1, 1, n_steps, n_features))\n","  model=fit_model(X, y, n_steps, n_features,node,epochs)\n","  yhat=model.predict(X,verbose=0)\n","  y=y.reshape(-1,5)\n","  test_y=test_y.reshape(-1,5)\n","\n","  train_error=rmse(yhat, y)\n","\n","  train_E.append(np.around(train_error,3))\n","\n","  test_yhat=model.predict(test_X,verbose=0)\n","  test_error=rmse(test_yhat, test_y)\n","  test_E.append(np.around(test_error,3))\n","\n","  Error1=[n_steps,node,epochs,list(train_E[0]),round(np.mean(train_E),3)]\n","  Error2=[n_steps,node,epochs,list(test_E[0]), round(np.mean(test_E), 3)]\n","\n","  global max\n","  if Error2[-1]<max:\n","    max=Error2[-1]\n","    print('Minimum: ',Error2)\n","    global E1\n","    global E2 \n","    E1=Error1\n","    E2=Error2\n","\n","  print(Error1)\n","  print(Error2)\n","\n","  return y, yhat, test_y, test_yhat\n","\n","  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XCFhfsmMNlF1"},"source":["max=10\n","E1=[]\n","E2=[]\n","for n_steps in range(3,12):\n","  for node in range(16,256,16):\n","    for epochs in range(2000,2001,100):\n","      model(n_steps,node,epochs)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fDdXO3KCJM8E"},"source":["print(E1)\n","print(E2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9CouY-IsgXhs"},"source":["model(2,16,50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5PWd0TaRJ0a_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bqszUvqzgOey"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dnk7hnLzghpA"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PJD3wfjMi4vx"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P6IFEnFgi59S"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wi4a3HkBjALu"},"source":[""],"execution_count":null,"outputs":[]}]}