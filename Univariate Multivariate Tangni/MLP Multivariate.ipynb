{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9900999f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: /physical_device:GPU:0   Type: GPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb55b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import pyswarms as ps\n",
    "import random\n",
    "from pylab import rcParams\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cdc4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f96a2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 50, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca8e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TEST_TRAIN_DATA = 'Tangni/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f24b8e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Tangni:\n",
    "    def __init__(self,dictionary):\n",
    "        \n",
    "        self.train_size = 62\n",
    "        \n",
    "        \n",
    "        self.data1 = np.array(pd.read_csv(PATH_TO_TEST_TRAIN_DATA + '1-3.csv',  header=0, usecols=[0, 1, 2, 3], index_col=None))\n",
    "        self.data2 = np.array(pd.read_csv(PATH_TO_TEST_TRAIN_DATA + '2-12.csv', header=0, usecols=[0, 1, 2, 3], index_col=None))\n",
    "        self.data3 = np.array(pd.read_csv(PATH_TO_TEST_TRAIN_DATA + '3-6.csv',  header=0, usecols=[0, 1, 2, 3], index_col=None))\n",
    "        self.data4 = np.array(pd.read_csv(PATH_TO_TEST_TRAIN_DATA + '4-15.csv', header=0, usecols=[0, 1, 2, 3], index_col=None))\n",
    "        self.data5 = np.array(pd.read_csv(PATH_TO_TEST_TRAIN_DATA + '5-15.csv', header=0, usecols=[0, 1, 2, 3], index_col=None))     \n",
    "        \n",
    "    def Print(self):\n",
    "        print(self.data1)\n",
    "        \n",
    "    def rmse(self, true, predict):\n",
    "        \n",
    "        r = true - predict\n",
    "        sq = r*r\n",
    "        avg = np.mean(sq)\n",
    "        error = math.sqrt(avg)\n",
    "\n",
    "        return error\n",
    "    \n",
    "    def Average(self, lst):\n",
    "        return sum(lst) / len(lst)\n",
    "    \n",
    "    def dataProcessing(self, dF, lookback):\n",
    "    \n",
    "        data=list()\n",
    "        label=list()\n",
    "        for i in range(len(dF) - lookback):\n",
    "\n",
    "            data.append(np.array(dF[i:i+lookback,:4]))\n",
    "\n",
    "            label.append(np.array(dF[i+lookback,1:2]))\n",
    "        \n",
    "        return np.array(data), np.array(label)\n",
    "\n",
    "    def make_packets(self, lookback):\n",
    "        \n",
    "        X1, L1 = self.dataProcessing(self.data1, lookback)\n",
    "        X2, L2 = self.dataProcessing(self.data2, lookback)\n",
    "        X3, L3 = self.dataProcessing(self.data3, lookback)\n",
    "        X4, L4 = self.dataProcessing(self.data4, lookback)\n",
    "        X5, L5 = self.dataProcessing(self.data5, lookback)\n",
    "        \n",
    "        train_X1, label_X1,test_X1,tst_label_X1 = X1[:self.train_size - lookback], L1[:self.train_size - lookback], X1[self.train_size - lookback:], L1[self.train_size - lookback:]\n",
    "        train_X2, label_X2,test_X2,tst_label_X2 = X2[:self.train_size - lookback], L2[:self.train_size - lookback], X2[self.train_size - lookback:], L2[self.train_size - lookback:]\n",
    "        train_X3, label_X3,test_X3,tst_label_X3 = X3[:self.train_size - lookback], L3[:self.train_size - lookback], X3[self.train_size - lookback:], L3[self.train_size - lookback:]\n",
    "        train_X4, label_X4,test_X4,tst_label_X4 = X4[:self.train_size - lookback], L4[:self.train_size - lookback], X4[self.train_size - lookback:], L4[self.train_size - lookback:]\n",
    "        train_X5, label_X5,test_X5,tst_label_X5 = X5[:self.train_size - lookback], L5[:self.train_size - lookback], X5[self.train_size - lookback:], L5[self.train_size - lookback:]\n",
    "        \n",
    "    \n",
    "        return train_X1, label_X1,test_X1,tst_label_X1, train_X2, label_X2,test_X2,tst_label_X2,train_X3, label_X3,test_X3,tst_label_X3, train_X4, label_X4,test_X4,tst_label_X4, train_X5, label_X5,test_X5,tst_label_X5\n",
    "\n",
    "    def getData(self, lookback = 1, shuffle=0):\n",
    "        \n",
    "        train_X1, label_X1,test_X1,tst_label_X1, train_X2, label_X2,test_X2,tst_label_X2,train_X3, label_X3,test_X3,tst_label_X3, train_X4, label_X4,test_X4,tst_label_X4, train_X5, label_X5,test_X5,tst_label_X5 = self.make_packets(lookback)\n",
    "        DATA = [train_X1, label_X1,test_X1,tst_label_X1, train_X2, label_X2,test_X2,tst_label_X2,train_X3, label_X3,test_X3,tst_label_X3, train_X4, label_X4,test_X4,tst_label_X4, train_X5, label_X5,test_X5,tst_label_X5]\n",
    "        \n",
    "        Train = np.append(train_X1, np.append(train_X2, np.append(train_X3, np.append(train_X4, train_X5, axis=0), axis=0), axis=0), axis=0)\n",
    "        Label = np.append(label_X1, np.append(label_X2, np.append(label_X3, np.append(label_X4, label_X5, axis=0), axis=0), axis=0), axis=0) \n",
    "     \n",
    "        if (shuffle == 1):\n",
    "            Train, Label = skshuffle(Train, Label, random_state=0)\n",
    "            \n",
    "        return Train, Label\n",
    "    \n",
    "    def MLP_model(self, units, lookback, features):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(units = units, activation= 'tanh', input_shape = (lookback, features)))\n",
    "        model.add(Dense(units = 1, activation= 'linear'))\n",
    "        model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "#         model.summary()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def trainModel(self, units, lookback = 1, batch_size = 4, shuffle = 0):\n",
    "        \n",
    "        train_X1, label_X1,test_X1,tst_label_X1, train_X2, label_X2,test_X2,tst_label_X2,train_X3, label_X3,test_X3,tst_label_X3, train_X4, label_X4,test_X4,tst_label_X4, train_X5, label_X5,test_X5,tst_label_X5 = self.make_packets(lookback)\n",
    "        DATA = [train_X1, label_X1,test_X1,tst_label_X1, train_X2, label_X2,test_X2,tst_label_X2,train_X3, label_X3,test_X3,tst_label_X3, train_X4, label_X4,test_X4,tst_label_X4, train_X5, label_X5,test_X5,tst_label_X5]\n",
    "        \n",
    "        Train = np.append(train_X1, np.append(train_X2, np.append(train_X3, np.append(train_X4, train_X5, axis=0), axis=0), axis=0), axis=0)\n",
    "        Label = np.append(label_X1, np.append(label_X2, np.append(label_X3, np.append(label_X4, label_X5, axis=0), axis=0), axis=0), axis=0) \n",
    "     \n",
    "        if (shuffle == 1):\n",
    "            Train, Label = skshuffle(Train, Label, random_state=0)\n",
    "            \n",
    "        MLP = self.MLP_model(units, lookback)\n",
    "        MLP.fit(Train, Label, epochs = 3, batch_size = batch_size, verbose=0)\n",
    "        \n",
    "        RMSE = list()\n",
    "        \n",
    "        #Calculate the error of the traing and testing\n",
    "        for i in range(0, 20, 2):\n",
    "            \n",
    "            prediction = MLP.predict(DATA[i])\n",
    "            RMSE.append(self.rmse(prediction, DATA[i+1]))\n",
    "           \n",
    "         \n",
    "        #Find average of the training and testing\n",
    "        RMSE.append(self.Average(RMSE[0:5]))\n",
    "        RMSE.append(self.Average(RMSE[5:10]))\n",
    "        \n",
    "      \n",
    "        return RMSE\n",
    "    \n",
    "    def accuracy(self, MLP, Data1, Data2, Data3, shape, r):\n",
    "        \n",
    "        P =[]\n",
    "           \n",
    "        if r==0:\n",
    "            D1 = np.copy(Data1[0])\n",
    "            D1=D1.reshape(shape)\n",
    "            D2 = np.copy(Data2[1:])\n",
    "            Testing = np.copy(Data3)\n",
    "            for i in range(len(D2)):\n",
    "                p=MLP.predict(D1)\n",
    "                P.append(p[-1][0])\n",
    "                a=np.array(D2[i])\n",
    "                a=a.reshape(shape)\n",
    "                D1=np.append(D1,a,axis=0)\n",
    "            P=np.array(P)\n",
    "            RMSE = math.sqrt(mean_squared_error(Testing[1:], P))\n",
    "            MAE  = mean_absolute_error(Testing[1:], P)\n",
    "            MAPE = mean_absolute_percentage_error(Testing[1:], P)\n",
    "            \n",
    "        if r==1:\n",
    "            D1 = np.copy(Data1)\n",
    "            D2 = np.copy(Data2)\n",
    "            Testing = np.copy(Data3)\n",
    "            for i in range(16):\n",
    "                p=MLP.predict(D1)\n",
    "                P.append(p[-1][0])\n",
    "                a=np.array(D2[i])\n",
    "                a=a.reshape(shape)\n",
    "                D1=np.append(D1,a,axis=0)\n",
    "            P=np.array(P)\n",
    "            RMSE = math.sqrt(mean_squared_error(Testing, P))\n",
    "            MAE  = mean_absolute_error(Testing, P)\n",
    "            MAPE = mean_absolute_percentage_error(Testing, P)\n",
    "            \n",
    "        return RMSE, MAE, MAPE, P\n",
    "    \n",
    "    def runModel(self, units, features, lookback = 1, epochs=1, batch_size = 4, shuffle = 0):\n",
    "        \n",
    "        train_X1, label_X1,test_X1,tst_label_X1, train_X2, label_X2,test_X2,tst_label_X2,train_X3, label_X3,test_X3,tst_label_X3, train_X4, label_X4,test_X4,tst_label_X4, train_X5, label_X5,test_X5,tst_label_X5 = self.make_packets(lookback)\n",
    "        DATA = [train_X1, label_X1,test_X1,tst_label_X1, train_X2, label_X2,test_X2,tst_label_X2,train_X3, label_X3,test_X3,tst_label_X3, train_X4, label_X4,test_X4,tst_label_X4, train_X5, label_X5,test_X5,tst_label_X5]\n",
    "        \n",
    "        Train = np.append(train_X1, np.append(train_X2, np.append(train_X3, np.append(train_X4, train_X5, axis=0), axis=0), axis=0), axis=0)\n",
    "        Label = np.append(label_X1, np.append(label_X2, np.append(label_X3, np.append(label_X4, label_X5, axis=0), axis=0), axis=0), axis=0) \n",
    "     \n",
    "        if (shuffle == 1):\n",
    "            Train, Label = skshuffle(Train, Label, random_state=0)\n",
    "        \n",
    "        MLP = self.MLP_model(units, lookback, features)\n",
    "        \n",
    "        MLP.fit(Train, Label, epochs = epochs, batch_size = batch_size, verbose=0)\n",
    "        \n",
    "        RMSE = []\n",
    "        MAE = []\n",
    "        MAPE = []\n",
    "        P =[]\n",
    "        Pre=[]\n",
    "        T =[]\n",
    "        sh = (1,lookback,features)\n",
    "        \n",
    "        #Calculate the error of the traing and testing\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X1,train_X1,label_X1,sh,r=0)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X2,train_X2,label_X2,sh,r=0)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X3,train_X3,label_X3,sh,r=0)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X4,train_X4,label_X4,sh,r=0)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X5,train_X5,label_X5,sh,r=0)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X1,test_X1,tst_label_X1,sh,r=1)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X2,test_X2,tst_label_X2,sh,r=1)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X3,test_X3,tst_label_X3,sh,r=1)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X4,test_X4,tst_label_X4,sh,r=1)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X5,test_X5,tst_label_X5,sh,r=1)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        RMSE.append(np.sum(RMSE[:5])/5)\n",
    "        RMSE.append(np.sum(RMSE[5:])/5)\n",
    "        \n",
    "        \n",
    "        return RMSE, MAE, MAPE, Pre\n",
    "    \n",
    "    def runModel_weights(self, units, features, weights, lookback = 1, epochs=1, batch_size = 4, shuffle = 0):\n",
    "        \n",
    "        train_X1, label_X1,test_X1,tst_label_X1, train_X2, label_X2,test_X2,tst_label_X2,train_X3, label_X3,test_X3,tst_label_X3, train_X4, label_X4,test_X4,tst_label_X4, train_X5, label_X5,test_X5,tst_label_X5 = self.make_packets(lookback)\n",
    "        DATA = [train_X1, label_X1,test_X1,tst_label_X1, train_X2, label_X2,test_X2,tst_label_X2,train_X3, label_X3,test_X3,tst_label_X3, train_X4, label_X4,test_X4,tst_label_X4, train_X5, label_X5,test_X5,tst_label_X5]\n",
    "        \n",
    "        Train = np.append(train_X1, np.append(train_X2, np.append(train_X3, np.append(train_X4, train_X5, axis=0), axis=0), axis=0), axis=0)\n",
    "        Label = np.append(label_X1, np.append(label_X2, np.append(label_X3, np.append(label_X4, label_X5, axis=0), axis=0), axis=0), axis=0) \n",
    "         \n",
    "        if (shuffle == 1):\n",
    "            Train, Label = skshuffle(Train, Label, random_state=0)\n",
    "        \n",
    "        MLP = self.MLP_model(units, lookback, features)\n",
    "        \n",
    "        idx1 = features * units\n",
    "        idx2 = idx1 + units\n",
    "        idx3 = idx2 + units\n",
    "        idx4 = idx3 + 1\n",
    "\n",
    "\n",
    "        W1 = weights[0:idx1].reshape((features, units))\n",
    "\n",
    "        W2 = weights[idx1:idx2].reshape((units))\n",
    "\n",
    "        W3 = weights[idx2:idx3].reshape((units,1))\n",
    "\n",
    "        W4 = weights[idx3:].reshape((1))\n",
    "\n",
    "\n",
    "        W = [W1,W2,W3,W4]\n",
    "\n",
    "\n",
    "        MLP.set_weights(W)\n",
    "        \n",
    "        MLP.fit(Train, Label, epochs = epochs, batch_size = batch_size, verbose=0)\n",
    "        \n",
    "        RMSE = []\n",
    "        MAE = []\n",
    "        MAPE = []\n",
    "        P =[]\n",
    "        Pre=[]\n",
    "        T =[]\n",
    "        sh = (1,lookback,features)\n",
    "        \n",
    "        #Calculate the error of the traing and testing\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X1,train_X1,label_X1,sh,r=0)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X2,train_X2,label_X2,sh,r=0)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X3,train_X3,label_X3,sh,r=0)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X4,train_X4,label_X4,sh,r=0)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X5,train_X5,label_X5,sh,r=0)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X1,test_X1,tst_label_X1,sh,r=1)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X2,test_X2,tst_label_X2,sh,r=1)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X3,test_X3,tst_label_X3,sh,r=1)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X4,test_X4,tst_label_X4,sh,r=1)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        A, B, C, D = self.accuracy(MLP,train_X5,test_X5,tst_label_X5,sh,r=1)\n",
    "        RMSE.append(A),MAE.append(B),MAPE.append(C),Pre.append(D)\n",
    "        \n",
    "        RMSE.append(np.sum(RMSE[:5])/5)\n",
    "        RMSE.append(np.sum(RMSE[5:])/5)\n",
    "        \n",
    "        \n",
    "        return RMSE, MAE, MAPE, Pre\n",
    "    \n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cad30e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {'normalize': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6712926",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP_Tangni(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3294e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfcc2cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89916576",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "\n",
    "        x, y = data\n",
    "        \n",
    "        y_pred = self(x, training=True)\n",
    "        loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "\n",
    "         # Compute our own metrics\n",
    "        loss_tracker.update_state(loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1043a4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a4dff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "783e4950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "def forward_props(params, units, features):\n",
    "    \n",
    "    idx1 = features * units\n",
    "    idx2 = idx1 + units\n",
    "    idx3 = idx2 + units\n",
    "    idx4 = idx3 + 1\n",
    "    \n",
    "    \n",
    "    W1 = params[0:idx1].reshape((features, units))\n",
    "   \n",
    "    W2 = params[idx1:idx2].reshape((units))\n",
    "    \n",
    "    W3 = params[idx2:idx3].reshape((units,1))\n",
    "    \n",
    "    W4 = params[idx3:].reshape((1))\n",
    "    \n",
    "\n",
    "    W = [W1,W2,W3,W4]\n",
    "   \n",
    "    modelOne.set_weights(W)\n",
    "\n",
    "    history = modelOne.fit(Train, Label, epochs = 1, batch_size = 1000, verbose=0)\n",
    "    \n",
    "    \n",
    "    loss = history.history['loss'][0]\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb1cf2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(x,print_step):\n",
    "\n",
    "    n_particles = x.shape[0]\n",
    "    j = [forward_props(x[i],units, features) for i in range(n_particles)]\n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b4f314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be129aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 11:44:50,050 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best: 100%|██████████████████████|100/100, best_cost=0.37\n",
      "2022-03-16 11:50:15,447 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.370383083820343\n",
      "2022-03-16 11:50:35,736 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 1] 0.45236625008373804 0.8086784609521024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.371\n",
      "2022-03-16 11:56:02,216 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.37060824036598206\n",
      "2022-03-16 11:56:22,443 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 1] 0.40762842717836517 0.9778943487876264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.509\n",
      "2022-03-16 12:01:43,328 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.5092293620109558\n",
      "2022-03-16 12:02:03,231 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 1] 0.40481593327201504 1.5600049067067736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.609\n",
      "2022-03-16 12:07:13,836 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.6086819171905518\n",
      "2022-03-16 12:07:32,946 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 1] 0.38476353015956477 1.3988788895753217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.537\n",
      "2022-03-16 12:12:37,775 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.5365852117538452\n",
      "2022-03-16 12:12:56,347 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300, 1] 0.4065561284560134 1.165389931251248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.942\n",
      "2022-03-16 12:18:00,046 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.9418685436248779\n",
      "2022-03-16 12:18:18,974 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400, 1] 0.44379242113257983 0.9790863582548106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|██████████████████████|100/100, best_cost=1.12\n",
      "2022-03-16 12:23:22,394 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 1.122155785560608\n",
      "2022-03-16 12:23:41,592 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500, 1] 0.41095253230401674 1.1399126972119784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.449\n",
      "2022-03-16 12:28:44,229 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.4491978585720062\n",
      "2022-03-16 12:29:03,155 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 2] 0.5558480484506999 1.3774183410337297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.515\n",
      "2022-03-16 12:34:08,981 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.5145005583763123\n",
      "2022-03-16 12:34:28,721 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 2] 0.4288219340217327 1.26202922966018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.487\n",
      "2022-03-16 12:39:39,405 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.48721930384635925\n",
      "2022-03-16 12:39:59,141 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 2] 0.42898093593935177 0.9326206600330508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.565\n",
      "2022-03-16 12:45:11,176 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.5652481317520142\n",
      "2022-03-16 12:45:30,359 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 2] 0.423050179042262 0.8996531300302717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████████|100/100, best_cost=1\n",
      "2022-03-16 12:50:37,412 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 1.0020426511764526\n",
      "2022-03-16 12:50:56,049 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300, 2] 0.4218854536629951 1.419674588209937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.639\n",
      "2022-03-16 12:56:01,723 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.638714075088501\n",
      "2022-03-16 12:56:20,561 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400, 2] 0.4092554588638294 1.1644057854915377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|██████████████████████|100/100, best_cost=1.24\n",
      "2022-03-16 13:01:32,345 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 1.2440317869186401\n",
      "2022-03-16 13:01:51,831 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500, 2] 0.4690595197352052 1.2225157538488791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.474\n",
      "2022-03-16 13:06:56,077 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.4741390347480774\n",
      "2022-03-16 13:07:14,776 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 3] 0.5713423646657294 1.039541841020372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.532\n",
      "2022-03-16 13:12:22,626 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.5316837430000305\n",
      "2022-03-16 13:12:41,639 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 3] 0.4549963036294475 1.2304363425673546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|██████████████████████|100/100, best_cost=0.65\n",
      "2022-03-16 13:17:55,551 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.6501681804656982\n",
      "2022-03-16 13:18:16,524 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 3] 0.4583476054764454 1.05449022967288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.605\n",
      "2022-03-16 13:23:19,448 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.6049515008926392\n",
      "2022-03-16 13:23:38,304 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 3] 0.4479999339803917 0.9986585496782322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.965\n",
      "2022-03-16 13:28:48,106 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.9645499587059021\n",
      "2022-03-16 13:29:06,933 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300, 3] 0.5040643637881816 0.9734259465246407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.861\n",
      "2022-03-16 13:34:16,395 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.860805332660675\n",
      "2022-03-16 13:34:35,371 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400, 3] 0.4743731744312504 0.9493581811885277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|██████████████████████|100/100, best_cost=1.04\n",
      "2022-03-16 13:39:41,458 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 1.039971947669983\n",
      "2022-03-16 13:40:00,458 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500, 3] 0.47621861391893416 1.136705360188683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.644\n",
      "2022-03-16 13:45:03,415 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.6442229151725769\n",
      "2022-03-16 13:45:22,051 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 4] 0.6039160261546845 0.9444603584285198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.581\n",
      "2022-03-16 13:50:25,691 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.5810040235519409\n",
      "2022-03-16 13:50:44,397 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 4] 0.47310805536895917 1.020302837953071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.629\n",
      "2022-03-16 13:55:47,261 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.6289516091346741\n",
      "2022-03-16 13:56:05,987 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 4] 0.46972968789046776 0.8960580945083649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|██████████████████████|100/100, best_cost=0.81\n",
      "2022-03-16 14:01:09,603 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.809760570526123\n",
      "2022-03-16 14:01:28,167 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 4] 0.4716275493974881 0.9615168159098675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.664\n",
      "2022-03-16 14:06:31,556 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.6643113493919373\n",
      "2022-03-16 14:06:50,061 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300, 4] 0.45238298225039414 0.9988998401914329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|██████████████████████|100/100, best_cost=1.38\n",
      "2022-03-16 14:11:53,711 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 1.3818364143371582\n",
      "2022-03-16 14:12:12,454 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400, 4] 0.616602195664818 0.9416306566930854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|██████████████████████|100/100, best_cost=1.38\n",
      "2022-03-16 14:17:16,950 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 1.3758963346481323\n",
      "2022-03-16 14:17:35,439 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500, 4] 0.5160402370758759 1.1142453792504416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.769\n",
      "2022-03-16 14:22:37,756 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.7688018679618835\n",
      "2022-03-16 14:22:55,892 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 5] 0.6494343138784338 0.9215586906106417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.662\n",
      "2022-03-16 14:27:59,507 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.6621991991996765\n",
      "2022-03-16 14:28:18,010 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 5] 0.49202730672492995 0.7974907717400577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.664\n",
      "2022-03-16 14:33:22,269 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.6643689274787903\n",
      "2022-03-16 14:33:41,084 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 5] 0.4967170662460407 0.866224364696602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.892\n",
      "2022-03-16 14:38:45,653 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.891904354095459\n",
      "2022-03-16 14:39:04,042 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 5] 0.5002840397271817 0.9048712419374283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.904\n",
      "2022-03-16 14:44:11,653 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.9042516946792603\n",
      "2022-03-16 14:44:30,518 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300, 5] 0.483433717524989 0.8712511101983701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|██████████████████████|100/100, best_cost=1.26\n",
      "2022-03-16 14:49:37,565 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 1.2610509395599365\n",
      "2022-03-16 14:49:55,800 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400, 5] 0.5157472004917055 0.9548990203672293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|██████████████████████|100/100, best_cost=1.28\n",
      "2022-03-16 14:54:56,245 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 1.2789278030395508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500, 5] 0.5356471622011365 1.1895836629259526\n",
      "--------------------------------------------------\n",
      "Minimimu Error at [units, lookback, shuffle]\n",
      "[200, 1, 0.38476353015956477, 1.3988788895753217]\n"
     ]
    }
   ],
   "source": [
    "lookback = [1,2,3,4,5]\n",
    "unitss = [10, 50, 100, 200, 300, 400, 500]\n",
    "Parameters = []\n",
    "Performance =[]\n",
    "minimum = 100\n",
    "idx = 0\n",
    "minidx = 0\n",
    "\n",
    "for i in lookback:\n",
    "        for u in unitss:\n",
    "\n",
    "            Parameters.append([u,i])\n",
    "\n",
    "            units = u\n",
    "            features = 4\n",
    "            \n",
    "            Train, Label =mlp.getData(lookback=i, shuffle=0)\n",
    "\n",
    "            inputs = keras.Input(shape=(i,features))\n",
    "            L = keras.layers.Dense(units = units, activation='tanh')(inputs)\n",
    "            outputs = keras.layers.Dense(1, activation='linear')(L)\n",
    "            modelOne = CustomModel(inputs, outputs)\n",
    "            modelOne.compile(optimizer=\"adam\", loss=\"mse\", metrics=['mae'])\n",
    "\n",
    "            # Initialize swarm\n",
    "            options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
    "\n",
    "            # Call instance of PSO\n",
    "\n",
    "            dimensions = features * units + units + units + 1\n",
    "            optimizer = ps.single.GlobalBestPSO(n_particles=100, dimensions=dimensions, options=options)\n",
    "\n",
    "            # Perform optimization\n",
    "            cost, pos = optimizer.optimize(fun, print_step=0, iters=100, verbose=1)\n",
    "\n",
    "            RMSE,MAE,MAPE,Pre = mlp.runModel_weights(units=u, features=4, weights=pos, lookback = i, epochs=1000, batch_size = 64, shuffle = 0)\n",
    "\n",
    "            print([u,i],RMSE[-2],RMSE[-1])\n",
    "            Performance.append([u,i,RMSE[-2],RMSE[-1]])\n",
    "\n",
    "            if RMSE[-2] < minimum:\n",
    "                minimum = RMSE[-2]\n",
    "                minidx = idx\n",
    "\n",
    "            idx += 1\n",
    "                \n",
    "print('--------------------------------------------------')\n",
    "print('Minimimu Error at [units, lookback, shuffle]')\n",
    "\n",
    "print(Performance[minidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d31e0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f02592b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 15:52:40,383 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best: 100%|█████████████████████|100/100, best_cost=0.524\n",
      "2022-03-16 15:57:44,773 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.5240565538406372\n"
     ]
    }
   ],
   "source": [
    "units = 200\n",
    "features = 4\n",
    "lookback = 1\n",
    "shuffle = 0\n",
    "\n",
    "Train, Label =mlp.getData(lookback=lookback, shuffle=shuffle)\n",
    "Train.shape\n",
    "\n",
    "inputs = keras.Input(shape=(lookback,features))\n",
    "L = keras.layers.Dense(units = units, activation='tanh')(inputs)\n",
    "outputs = keras.layers.Dense(1, activation='linear')(L)\n",
    "modelOne = CustomModel(inputs, outputs)\n",
    "modelOne.compile(optimizer=\"adam\", loss=\"mse\", metrics=['mae'])\n",
    "\n",
    "# Initialize swarm\n",
    "options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
    "\n",
    "# Call instance of PSO\n",
    "\n",
    "dimensions = features * units + units + units + 1\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=100, dimensions=dimensions, options=options)\n",
    "\n",
    "# Perform optimization\n",
    "cost, posfinal = optimizer.optimize(fun, print_step =0, iters=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e3624c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d328174",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE,MAE,MAPE,Pre = mlp.runModel_weights(units=200, features=4, weights=posfinal, lookback = 1, epochs=500, batch_size = 4, shuffle = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ea7762f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8905497424602841,\n",
       " 0.15288159719355143,\n",
       " 0.10743044352123683,\n",
       " 0.33145827073747747,\n",
       " 0.6844146872991569,\n",
       " 0.7582724977482556,\n",
       " 1.1349631042705448,\n",
       " 1.9229989368005111,\n",
       " 1.331497836077505,\n",
       " 1.7563219294880854,\n",
       " 0.4333469482423413,\n",
       " 1.4674802505254487]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e476cc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8905497424602841 0.15288159719355143 0.10743044352123683 0.33145827073747747 0.6844146872991569 0.7582724977482556 1.1349631042705448 1.9229989368005111 1.331497836077505 1.7563219294880854\n",
      "0.3136245220904292 0.1118177214665813 0.0838961102702346 0.20066332215474744 0.4106892470614829 0.5790022530604095 0.9449916892864549 1.0051248445976173 1.1538228762493363 1.5854977843239\n",
      "0.3148150369970095 0.04543743594096391 37.87253429781962 0.08050648417429894 0.7612466142290231 0.10466363740001605 0.38399994905574364 5.292784027665974 0.3518169598491294 1.0943983919462386\n"
     ]
    }
   ],
   "source": [
    "print(RMSE[0],RMSE[1],RMSE[2],RMSE[3],RMSE[4],RMSE[5],RMSE[6],RMSE[7],RMSE[8],RMSE[9])\n",
    "print(MAE[0],MAE[1],MAE[2],MAE[3],MAE[4],MAE[5],MAE[6],MAE[7],MAE[8],MAE[9])\n",
    "print(MAPE[0],MAPE[1],MAPE[2],MAPE[3],MAPE[4],MAPE[5],MAPE[6],MAPE[7],MAPE[8],MAPE[9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a43100b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE,MAE,MAPE,Pre = mlp.runModel(units=100, features=4, lookback = 2, epochs=500, batch_size = 4, shuffle = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cda20497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9772865786367941,\n",
       " 0.11545894175284986,\n",
       " 0.10101558938118688,\n",
       " 0.395433731165278,\n",
       " 0.741474673180304,\n",
       " 0.5477077271948322,\n",
       " 0.5765579973369848,\n",
       " 1.7238234667856875,\n",
       " 0.8826090039721531,\n",
       " 1.6520755638342064,\n",
       " 0.4661339028232826,\n",
       " 1.1697815323894294]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff7a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
