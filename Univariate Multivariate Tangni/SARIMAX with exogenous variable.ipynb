{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9900999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from numpy import mean\n",
    "import numpy as np\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib\n",
    "from IPython.display import display, HTML\n",
    "import pandas\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "start=0\n",
    "cfg_list=list()\n",
    "def measure_rmse(actual, predicted,error=0):\n",
    "    if len(actual)!=len(predicted):\n",
    "        print(\"Length of data is not equals\")\n",
    "    error=sqrt(mean_squared_error(actual, predicted))\n",
    "    return error\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "def sarima_forecast(history, Ex, config):\n",
    "    order, sorder, trend = config\n",
    "    model = SARIMAX(endog=history, exog= Ex, order=order, seasonal_order=sorder, trend=trend)\n",
    "    model_fit = model.fit(disp=False)\n",
    "    yhat = model_fit.predict(len(history),len(history),  exog=Ex[-1])\n",
    "\n",
    "    return yhat[0]\n",
    "\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    train1, test1 = train_test_split(data, n_test)\n",
    "    label = [x for x in train1[6:,1]]\n",
    "    train = [x for x in train1[:,1]]\n",
    "    test = [x for x in test1[:,1]]\n",
    "    Ex_train =  [[x[0],x[2],x[3]] for x in train1[:6]]\n",
    "\n",
    "    history = [x for x in train[:6]]\n",
    "    for i in range(6,len(train1)):\n",
    "        yhat = sarima_forecast(history,Ex_train, cfg)\n",
    "        predictions.append(yhat)\n",
    "        history.append(train[i])\n",
    "        Ex_train.append([train1[i][0],train1[i][2],train1[i][3]])\n",
    "        \n",
    "\n",
    "    error = measure_rmse(label, predictions)\n",
    "\n",
    "    return error\n",
    "\n",
    "def score_model(data, n_test, cfg,count, debug=False):\n",
    "    result = None\n",
    "    error_resi=list()\n",
    "    error_trains=list()\n",
    "    error_tests=list()\n",
    "    \n",
    "    key = (cfg)\n",
    "\n",
    "    try:\n",
    "        with catch_warnings():\n",
    "            filterwarnings(\"ignore\")\n",
    "            error_tests = walk_forward_validation(data, n_test, cfg)\n",
    "    except:\n",
    "        error_tests=10\n",
    "        \n",
    "    return (key, error_tests)\n",
    "\n",
    "def parallel_model(data1,data2,data3,data4,data5, n_test, cfg,count):\n",
    "    score=[]\n",
    "    global start\n",
    "    start=start+1\n",
    "    \n",
    "    score1=score_model(data1, n_test, cfg, len(cfg_list))\n",
    "    score2=score_model(data2, n_test, cfg, len(cfg_list))\n",
    "    score3=score_model(data3, n_test, cfg, len(cfg_list))\n",
    "    score4=score_model(data4, n_test, cfg, len(cfg_list))\n",
    "    score5=score_model(data5, n_test, cfg, len(cfg_list))\n",
    "    bh1=score1[1]\n",
    "    bh2=score2[1]\n",
    "    bh3=score3[1]\n",
    "    bh4=score4[1]\n",
    "    bh5=score5[1]\n",
    "\n",
    "    avg_test=(bh1+bh2+bh3+bh4+bh5)/5\n",
    "    score=[score1[0],round(bh1,3),round(bh2,3),round(bh3,3),round(bh4,3),round(bh5,3),round(avg_test,5)]\n",
    "    \n",
    "    if avg_test<10:\n",
    "        print( '[%s/%s]> Model[%s] [%.5f]' % (int(start/5)+1,count,score1[0],avg_test))\n",
    "        \n",
    "\n",
    "    return score\n",
    "\n",
    "def grid_search(data1,data2,data3,data4,data5, cfg_list, n_test,count, parallel=True):\n",
    "    scores = []\n",
    "    \n",
    "    if parallel:\n",
    "#         executor = Parallel(n_jobs=cpu_count(), backend= 'multiprocessing' )\n",
    "        executor = Parallel(n_jobs=1000, backend= 'multiprocessing' )\n",
    "        tasks = (delayed(parallel_model)(data1,data2,data3,data4,data5, n_test, cfg, count) for cfg in cfg_list)\n",
    "        scores = executor(tasks)\n",
    "    else:\n",
    "        for cfg in cfg_list:\n",
    "            scores=parallel_model(data1,data2,data3,data4,data5, n_test, cfg, count)\n",
    "    \n",
    "\n",
    "    scores = [r for r in scores if r[6] <10]\n",
    "    scores.sort(key=lambda tup: tup[6])\n",
    "    return scores \n",
    "\n",
    "\n",
    "\n",
    "def find_best_models(data1,data2,data3,data4,data5):\n",
    "\n",
    "    # data split\n",
    "    n_test = 16\n",
    "    count=0\n",
    "    \n",
    "    scores=list()\n",
    "    # # model configs\n",
    "    cfg_list,count = sarima_configs()    \n",
    "\n",
    "    # # grid searchech blog\n",
    "\n",
    "    scores = grid_search(data1,data2,data3,data4,data5, cfg_list, n_test,count)\n",
    "    df = pandas.DataFrame(scores)\n",
    "    df.to_csv(\"output.csv\", sep=',',index=False)\n",
    "    print('-----------------------------------------------------------------------------')\n",
    "    print('\\t \\t cfg \\t\\t BH1  BH2   BH3     BH4    BH5   AVG')\n",
    "    print('-----------------------------------------------------------------------------')\n",
    "    for i in range(len(scores)):\n",
    "        print(scores[i])\n",
    "    print('-----------------------------------------------------------------------------')   \n",
    "    return scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfba19c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb55b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure(train1,test1,train2,test2,train3,test3,train4,test4,train5,test5,predictions_train1,predictions_train2,predictions_train3,predictions_train4,predictions_train5,predictions_test1,predictions_test2,predictions_test3,predictions_test4,predictions_test5,error_train1,error_train2,error_train3,error_train4,error_train5,error_test1,error_test2,error_test3,error_test4,error_test5):\n",
    "    fig= plt.figure(figsize=(14, 25))\n",
    "\n",
    "    params = {'legend.fontsize': 12,\n",
    "              'legend.handlelength': 2,\n",
    "              'font.size': 12}\n",
    "    plt.rcParams.update(params)\n",
    "    degree_sign= u'\\N{DEGREE SIGN}'\n",
    "\n",
    "    sub1 = plt.subplot(5, 2, 1)\n",
    "    plt.plot(train1,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_train1,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TRAIN\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.ylim(-7,2)\n",
    "    trn_rmse=\"RMSE: \"+str(format(error_train1,'.2f'))\n",
    "    plt.text(45, -6.5, trn_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"A\",fontsize=20,fontweight='bold')\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    sub2 = plt.subplot(5, 2, 2)\n",
    "    # sub2.set_yticks([1,0,-1,-2,-3,-4,-5,-6])\n",
    "    plt.plot(test1,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_test1,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TEST\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    plt.ylim(-7,2)\n",
    "    # place a text box in lower right in axes coords\n",
    "    tst_rmse=\"RMSE: \"+str(format(error_test1,'.2f'))\n",
    "    plt.text(11, -6.5, tst_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"B\",fontsize=20,fontweight='bold')\n",
    "\n",
    "    sub3 = plt.subplot(5, 2, 3)\n",
    "    plt.plot(train2,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_train2,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TRAIN\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.ylim(-7,2)\n",
    "    trn_rmse=\"RMSE: \"+str(format(error_train2,'.2f'))\n",
    "    plt.text(45, -6.5, trn_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"C\",fontsize=20,fontweight='bold')\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    sub4 = plt.subplot(5, 2, 4)\n",
    "    # sub2.set_yticks([1,0,-1,-2,-3,-4,-5,-6])\n",
    "    plt.plot(test2,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_test2,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TEST\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    plt.ylim(-7,2)\n",
    "    # place a text box in lower right in axes coords\n",
    "    tst_rmse=\"RMSE: \"+str(format(error_test2,'.2f'))\n",
    "    plt.text(11, -6.5, tst_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"D\",fontsize=20,fontweight='bold')\n",
    "\n",
    "    sub5 = plt.subplot(5, 2, 5)\n",
    "    plt.plot(train3,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_train3,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TRAIN\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.ylim(-7,2)\n",
    "    trn_rmse=\"RMSE: \"+str(format(error_train3,'.2f'))\n",
    "    plt.text(45, -6.5, trn_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"E\",fontsize=20,fontweight='bold')\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    sub6 = plt.subplot(5, 2, 6)\n",
    "    # sub2.set_yticks([1,0,-1,-2,-3,-4,-5,-6])\n",
    "    plt.plot(test3,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_test3,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TEST\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    plt.ylim(-7,2)\n",
    "    # place a text box in lower right in axes coords\n",
    "    tst_rmse=\"RMSE: \"+str(format(error_test3,'.2f'))\n",
    "    plt.text(11, -6.5, tst_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"F\",fontsize=20,fontweight='bold')\n",
    "\n",
    "    sub7 = plt.subplot(5, 2, 7)\n",
    "    plt.plot(train4,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_train4,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TRAIN\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.ylim(-7,2)\n",
    "    trn_rmse=\"RMSE: \"+str(format(error_train4,'.2f'))\n",
    "    plt.text(45, -6.5, trn_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"G\",fontsize=20,fontweight='bold')\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    sub8 = plt.subplot(5, 2, 8)\n",
    "    # sub2.set_yticks([1,0,-1,-2,-3,-4,-5,-6])\n",
    "    plt.plot(test4,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_test4,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TEST\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    plt.ylim(-7,2)\n",
    "    # place a text box in lower right in axes coords\n",
    "    tst_rmse=\"RMSE: \"+str(format(error_test4,'.2f'))\n",
    "    plt.text(11, -6.5, tst_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"H\",fontsize=20,fontweight='bold')\n",
    "\n",
    "    sub9 = plt.subplot(5, 2, 9)\n",
    "    plt.plot(train5,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_train5,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TRAIN\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.ylim(-7,2)\n",
    "    trn_rmse=\"RMSE: \"+str(format(error_train5,'.2f'))\n",
    "    plt.text(45, -6.5, trn_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"I\",fontsize=20,fontweight='bold')\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    sub10 = plt.subplot(5, 2, 10)\n",
    "    # sub2.set_yticks([1,0,-1,-2,-3,-4,-5,-6])\n",
    "    plt.plot(test5,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_test5,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TEST\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    plt.ylim(-7,2)\n",
    "    # place a text box in lower right in axes coords\n",
    "    tst_rmse=\"RMSE: \"+str(format(error_test5,'.2f'))\n",
    "    plt.text(11, -6.5, tst_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"J\",fontsize=20,fontweight='bold')\n",
    "\n",
    "    plt.savefig(\"SARIMABH.svg\",bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def sarima_test(data, n_test, cfg):\n",
    "    \n",
    "    \n",
    "    predictions_test = []\n",
    "    predictions_train = []\n",
    "    train1, test1 = train_test_split(data, n_test)\n",
    "    \n",
    "    label_train = [x for x in train1[6:,1]]\n",
    "    \n",
    "    label_test = [x for x in test1[:,1]] \n",
    "    \n",
    "    history_train = [x for x in train1[:6,1]]\n",
    "    history_test = [x for x in train1[:,1]]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    Ex_train =  [[x[0],x[2],x[3]] for x in train1[:6]]\n",
    "    Ex_test =   [[x[0],x[2],x[3]] for x in train1[:]]\n",
    "    \n",
    "\n",
    "    for i in range(6,len(train1)):\n",
    "        yhat = sarima_forecast(history_train, Ex_train,cfg)\n",
    "        \n",
    "        predictions_train.append(yhat)\n",
    "        history_train.append(train1[i][1])\n",
    "        Ex_train.append([train1[i][0],train1[i][2],train1[i][3]])\n",
    "        \n",
    "      \n",
    "    error_train = measure_rmse(label_train, predictions_train)\n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range(len(test1)):\n",
    "        yhat = sarima_forecast(history_test, Ex_test, cfg)\n",
    "        predictions_test.append(yhat)\n",
    "        history_test.append(test1[i][1])\n",
    "        Ex_test.append([test1[i][0],test1[i][2],test1[i][3]])\n",
    "        \n",
    "    error_test = measure_rmse(label_test, predictions_test)\n",
    "   \n",
    "    \n",
    "    return predictions_train, predictions_test, error_train, error_test\n",
    "\n",
    "\n",
    "\n",
    "def find(data1,data2,data3,data4,data5, n_test, cfg):\n",
    "    \n",
    "    predictions_train1, predictions_test1, error_train1, error_test1=sarima_test(data1, n_test, cfg)\n",
    "    try:\n",
    "        # never show warnings when grid searching, too noisy\n",
    "        with catch_warnings():\n",
    "            filterwarnings(\"ignore\")\n",
    "            predictions_train1, predictions_test1, error_train1, error_test1=sarima_test(data1, n_test, cfg)\n",
    "            predictions_train2, predictions_test2, error_train2, error_test2=sarima_test(data2, n_test, cfg)\n",
    "            predictions_train3, predictions_test3, error_train3, error_test3=sarima_test(data3, n_test, cfg)\n",
    "            predictions_train4, predictions_test4, error_train4, error_test4=sarima_test(data4, n_test, cfg)\n",
    "            predictions_train5, predictions_test5, error_train5, error_test5=sarima_test(data5, n_test, cfg)\n",
    "            avg_train=(error_train1+error_train2+error_train3+error_train4+error_train5)/5\n",
    "            avg_test=(error_test1+error_test2+error_test3+error_test4+error_test5)/5\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return predictions_train1,predictions_train2,predictions_train3,predictions_train4,predictions_train5,predictions_test1,predictions_test2,predictions_test3,predictions_test4,predictions_test5,error_train1,error_train2,error_train3,error_train4,error_train5,error_test1,error_test2,error_test3,error_test4,error_test5,avg_train,avg_test\n",
    "\n",
    "def best_model(data1,data2,data3,data4,data5,scores):\n",
    "    # data split\n",
    "    n_test = 16\n",
    "\n",
    "    cfg=scores[0][0]\n",
    "\n",
    "\n",
    "    train1,test1=train_test_split(data1, n_test)\n",
    "    train2,test2=train_test_split(data2, n_test)\n",
    "    train3,test3=train_test_split(data3, n_test)\n",
    "    train4,test4=train_test_split(data4, n_test)\n",
    "    train5,test5=train_test_split(data5, n_test)\n",
    "\n",
    "    predictions_train1,predictions_train2,predictions_train3,predictions_train4,predictions_train5,predictions_test1,predictions_test2,predictions_test3,predictions_test4,predictions_test5,error_train1,error_train2,error_train3,error_train4,error_train5,error_test1,error_test2,error_test3,error_test4,error_test5,avg_train,avg_test = find(data1,data2,data3,data4,data5, n_test, cfg)\n",
    "\n",
    "    print('________________________________________________________________________________________________')\n",
    "    print('| BH1\\t| BH1\\t| BH2\\t| BH2\\t| BH3\\t| BH3\\t| BH4\\t| BH4\\t| BH5\\t| BH5\\t| Train\\t| Test |')\n",
    "    print('________________________________________________________________________________________________')\n",
    "    print( '|%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f |' % (error_train1,error_test1,error_train2,error_test2,error_train3,error_test3,error_train4,error_test4,error_train5,error_test5,avg_train,avg_test))\n",
    "    print('________________________________________________________________________________________________')\n",
    "    error_train1 = mean_absolute_error(train1[6:,1],predictions_train1)\n",
    "    error_train2 = mean_absolute_error(train2[6:,1],predictions_train2)\n",
    "    error_train3 = mean_absolute_error(train3[6:,1],predictions_train3)\n",
    "    error_train4 = mean_absolute_error(train4[6:,1],predictions_train4)\n",
    "    error_train5 = mean_absolute_error(train5[6:,1],predictions_train5)\n",
    "    error_test1  = mean_absolute_error(test1[:,1],predictions_test1)\n",
    "    error_test2  = mean_absolute_error(test2[:,1],predictions_test2)\n",
    "    error_test3  = mean_absolute_error(test3[:,1],predictions_test3)\n",
    "    error_test4  = mean_absolute_error(test4[:,1],predictions_test4)\n",
    "    error_test5  = mean_absolute_error(test5[:,1],predictions_test5)\n",
    "    avg_train    = (error_train1+error_train2+error_train3+error_train4+error_train5)/5\n",
    "    avg_test     = (error_test1+error_test2+error_test3+error_test4+error_test5)/5\n",
    "    print( '|%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f |' % (error_train1,error_test1,error_train2,error_test2,error_train3,error_test3,error_train4,error_test4,error_train5,error_test5,avg_train,avg_test))\n",
    "    print('________________________________________________________________________________________________')\n",
    "    \n",
    "    error_train1 = mean_absolute_percentage_error(train1[6:,1],predictions_train1)\n",
    "    error_train2 = mean_absolute_percentage_error(train2[6:,1],predictions_train2)\n",
    "    error_train3 = mean_absolute_percentage_error(train3[6:,1],predictions_train3)\n",
    "    error_train4 = mean_absolute_percentage_error(train4[6:,1],predictions_train4)\n",
    "    error_train5 = mean_absolute_percentage_error(train5[6:,1],predictions_train5)\n",
    "    error_test1  = mean_absolute_percentage_error(test1[:,1],predictions_test1)\n",
    "    error_test2  = mean_absolute_percentage_error(test2[:,1],predictions_test2)\n",
    "    error_test3  = mean_absolute_percentage_error(test3[:,1],predictions_test3)\n",
    "    error_test4  = mean_absolute_percentage_error(test4[:,1],predictions_test4)\n",
    "    error_test5  = mean_absolute_percentage_error(test5[:,1],predictions_test5)\n",
    "    avg_train    = (error_train1+error_train2+error_train3+error_train4+error_train5)/5\n",
    "    avg_test     = (error_test1+error_test2+error_test3+error_test4+error_test5)/5\n",
    "    print( '|%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f |' % (error_train1,error_test1,error_train2,error_test2,error_train3,error_test3,error_train4,error_test4,error_train5,error_test5,avg_train,avg_test))\n",
    "    print('________________________________________________________________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cdc4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TEST_TRAIN_DATA = 'Tangni/Data/'\n",
    "\n",
    "#### define dataset\n",
    "series1 = read_csv(PATH_TO_TEST_TRAIN_DATA + '1-3.csv', header=0, usecols=[0,1,2,3], index_col=None) \n",
    "data1 = series1.values\n",
    "\n",
    "series2 = read_csv(PATH_TO_TEST_TRAIN_DATA + '2-12.csv', header=0, usecols=[0,1,2,3], index_col=None) \n",
    "data2 = series2.values\n",
    "\n",
    "series3 = read_csv(PATH_TO_TEST_TRAIN_DATA + '3-6.csv', header=0, usecols=[0,1,2,3], index_col=None) \n",
    "data3 = series3.values\n",
    "\n",
    "series4 = read_csv(PATH_TO_TEST_TRAIN_DATA + '4-15.csv', header=0, usecols=[0,1,2,3], index_col=None) \n",
    "data4 = series4.values\n",
    "\n",
    "series5 = read_csv(PATH_TO_TEST_TRAIN_DATA + '5-15.csv', header=0, usecols=[0,1,2,3], index_col=None) \n",
    "data5 = series5.values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdd5d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f96a2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarima_configs(seasonal=[0]):\n",
    "    models = list()\n",
    "    count=0\n",
    "    # define config lists \n",
    "    p_params = [0]\n",
    "    d_params = [1]\n",
    "    q_params = [1]\n",
    "    t_params = ['n']\n",
    "    P_params = [0]\n",
    "    D_params = [0]\n",
    "    Q_params = [0]\n",
    "    m_params = [0]\n",
    "    # create config instances\n",
    "    for p in p_params:\n",
    "        for d in d_params:\n",
    "            for q in q_params:\n",
    "                for t in t_params:\n",
    "                    for P in P_params:\n",
    "                        for D in D_params:\n",
    "                            for Q in Q_params:\n",
    "                                for m in m_params:\n",
    "                                    cfg = [(p,d,q), (P,D,Q,m), t]\n",
    "                                    models.append(cfg)\n",
    "                                    count=count+1\n",
    "    \n",
    "    return models,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c75d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83d798e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1]> Model[[(0, 1, 1), (0, 0, 0, 0), 'n']] [0.39329]\n",
      "-----------------------------------------------------------------------------\n",
      "\t \t cfg \t\t BH1  BH2   BH3     BH4    BH5   AVG\n",
      "-----------------------------------------------------------------------------\n",
      "[[(0, 1, 1), (0, 0, 0, 0), 'n'], 0.964, 0.044, 0.019, 0.058, 0.881, 0.39329]\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "scores=find_best_models(data1,data2,data3,data4,data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03665829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 1), (0, 0, 0, 0), 'n']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745ec6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e729b683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/terminator/anaconda3/envs/py38/lib/python3.8/site-packages/statsmodels/tsa/statespace/sarimax.py:975: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "/home/terminator/anaconda3/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:567: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warn(\"Maximum Likelihood optimization failed to converge. \"\n",
      "/home/terminator/anaconda3/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:567: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warn(\"Maximum Likelihood optimization failed to converge. \"\n",
      "/home/terminator/anaconda3/envs/py38/lib/python3.8/site-packages/statsmodels/base/model.py:567: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warn(\"Maximum Likelihood optimization failed to converge. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________\n",
      "| BH1\t| BH1\t| BH2\t| BH2\t| BH3\t| BH3\t| BH4\t| BH4\t| BH5\t| BH5\t| Train\t| Test |\n",
      "________________________________________________________________________________________________\n",
      "|0.964  |0.014  |0.044  |0.006  |0.019  |0.520  |0.058  |0.066  |0.881  |1.150  |0.393  |0.351 |\n",
      "________________________________________________________________________________________________\n",
      "|0.340  |0.014  |0.023  |0.006  |0.009  |0.213  |0.028  |0.039  |0.450  |0.770  |0.170  |0.208 |\n",
      "________________________________________________________________________________________________\n",
      "|0.467  |0.003  |0.009  |0.003  |3.591  |0.276  |0.009  |0.012  |0.804  |0.719  |0.976  |0.202 |\n",
      "________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model(data1,data2,data3,data4,data5,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "043340b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 0), (0, 0, 0, 0), 'n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48f400e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
