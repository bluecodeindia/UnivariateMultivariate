{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9900999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from numpy import mean\n",
    "import numpy as np\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib\n",
    "from IPython.display import display, HTML\n",
    "import pandas\n",
    "\n",
    "start=0\n",
    "cfg_list=list()\n",
    "def measure_rmse(actual, predicted,error=0):\n",
    "    error=sqrt(mean_squared_error(actual, predicted))\n",
    "    return error\n",
    "\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "def sarima_forecast(history, config):\n",
    "    order, sorder, trend = config\n",
    "    \n",
    "    model = SARIMAX(history, order=order, seasonal_order=sorder, trend=trend, enforce_stationarity=False, enforce_invertibility=False)\n",
    "    model_fit = model.fit(disp=False)\n",
    "    yhat = model_fit.predict(len(history), len(history))\n",
    "    return yhat[0]\n",
    "\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    history = [x for x in train]\n",
    "    for i in range(len(test)):\n",
    "        yhat = sarima_forecast(history, cfg)\n",
    "        predictions.append(yhat)\n",
    "        history.append(test[i])\n",
    "    error = measure_rmse(test, predictions)\n",
    "    return error\n",
    "\n",
    "def score_model(data, n_test, cfg,count, debug=False):\n",
    "    result = None\n",
    "    error_resi=list()\n",
    "    error_trains=list()\n",
    "    error_tests=list()\n",
    "    \n",
    "    key = (cfg)\n",
    "\n",
    "    try:\n",
    "        with catch_warnings():\n",
    "            filterwarnings(\"ignore\")\n",
    "            error_tests = walk_forward_validation(data, n_test, cfg)\n",
    "    except:\n",
    "        error_tests=10\n",
    "        \n",
    "    return (key, error_tests)\n",
    "\n",
    "def parallel_model(data1,data2,data3,data4,data5, n_test, cfg,count):\n",
    "    score=[]\n",
    "    global start\n",
    "    start=start+1\n",
    "    \n",
    "    score1=score_model(data1, n_test, cfg, len(cfg_list))\n",
    "    score2=score_model(data2, n_test, cfg, len(cfg_list))\n",
    "    score3=score_model(data3, n_test, cfg, len(cfg_list))\n",
    "    score4=score_model(data4, n_test, cfg, len(cfg_list))\n",
    "    score5=score_model(data5, n_test, cfg, len(cfg_list))\n",
    "    bh1=score1[1]\n",
    "    bh2=score2[1]\n",
    "    bh3=score3[1]\n",
    "    bh4=score4[1]\n",
    "    bh5=score5[1]\n",
    "\n",
    "    avg_test=(bh1+bh2+bh3+bh4+bh5)/5\n",
    "    score=(score1[0],round(bh1,3),round(bh2,3),round(bh3,3),round(bh4,3),round(bh5,3),round(avg_test,5))\n",
    "    \n",
    "    if avg_test<10:\n",
    "        print( '[%s/%s]> Model[%s] [%.5f]' % (int(start/5)+1,count,score1[0],avg_test))\n",
    "        \n",
    "\n",
    "    return score\n",
    "\n",
    "def grid_search(data1,data2,data3,data4,data5, cfg_list, n_test,count, parallel=True):\n",
    "    scores = []\n",
    "    \n",
    "    if parallel:\n",
    "        executor = Parallel(n_jobs=cpu_count(), backend= 'multiprocessing' )\n",
    "        tasks = (delayed(parallel_model)(data1,data2,data3,data4,data5, n_test, cfg, count) for cfg in cfg_list)\n",
    "        scores = executor(tasks)\n",
    "    else:\n",
    "        for cfg in cfg_list:\n",
    "            scores=parallel_model(data1,data2,data3,data4,data5, n_test, cfg, count)\n",
    "            \n",
    "    scores = [r for r in scores if r[6] <10]\n",
    "    scores.sort(key=lambda tup: tup[6])\n",
    "    return scores \n",
    "\n",
    "\n",
    "\n",
    "def find_best_models(data1,data2,data3,data4,data5):\n",
    "\n",
    "    # data split\n",
    "    n_test = 16\n",
    "    count=0\n",
    "    \n",
    "    scores=list()\n",
    "    # # model configs\n",
    "    cfg_list,count = sarima_configs()    \n",
    "\n",
    "    # # grid searchech blog\n",
    "\n",
    "    scores = grid_search(data1,data2,data3,data4,data5, cfg_list, n_test,count)\n",
    "    df = pandas.DataFrame(scores)\n",
    "    df.to_csv(\"output.csv\", sep=',',index=False)\n",
    "    print('-----------------------------------------------------------------------------')\n",
    "    print('\\t \\t cfg \\t\\t BH1  BH2   BH3     BH4    BH5   AVG')\n",
    "    print('-----------------------------------------------------------------------------')\n",
    "    for i in range(len(scores)):\n",
    "        print(scores[i])\n",
    "    print('-----------------------------------------------------------------------------')   \n",
    "    return scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bb55b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure(train1,test1,train2,test2,train3,test3,train4,test4,train5,test5,predictions_train1,predictions_train2,predictions_train3,predictions_train4,predictions_train5,predictions_test1,predictions_test2,predictions_test3,predictions_test4,predictions_test5,error_train1,error_train2,error_train3,error_train4,error_train5,error_test1,error_test2,error_test3,error_test4,error_test5):\n",
    "    fig= plt.figure(figsize=(14, 25))\n",
    "\n",
    "    params = {'legend.fontsize': 12,\n",
    "              'legend.handlelength': 2,\n",
    "              'font.size': 12}\n",
    "    plt.rcParams.update(params)\n",
    "    degree_sign= u'\\N{DEGREE SIGN}'\n",
    "\n",
    "    sub1 = plt.subplot(5, 2, 1)\n",
    "    plt.plot(train1,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_train1,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TRAIN\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.ylim(-7,2)\n",
    "    trn_rmse=\"RMSE: \"+str(format(error_train1,'.2f'))\n",
    "    plt.text(45, -6.5, trn_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"A\",fontsize=20,fontweight='bold')\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    sub2 = plt.subplot(5, 2, 2)\n",
    "    # sub2.set_yticks([1,0,-1,-2,-3,-4,-5,-6])\n",
    "    plt.plot(test1,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_test1,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TEST\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    plt.ylim(-7,2)\n",
    "    # place a text box in lower right in axes coords\n",
    "    tst_rmse=\"RMSE: \"+str(format(error_test1,'.2f'))\n",
    "    plt.text(11, -6.5, tst_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"B\",fontsize=20,fontweight='bold')\n",
    "\n",
    "    sub3 = plt.subplot(5, 2, 3)\n",
    "    plt.plot(train2,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_train2,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TRAIN\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.ylim(-7,2)\n",
    "    trn_rmse=\"RMSE: \"+str(format(error_train2,'.2f'))\n",
    "    plt.text(45, -6.5, trn_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"C\",fontsize=20,fontweight='bold')\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    sub4 = plt.subplot(5, 2, 4)\n",
    "    # sub2.set_yticks([1,0,-1,-2,-3,-4,-5,-6])\n",
    "    plt.plot(test2,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_test2,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TEST\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    plt.ylim(-7,2)\n",
    "    # place a text box in lower right in axes coords\n",
    "    tst_rmse=\"RMSE: \"+str(format(error_test2,'.2f'))\n",
    "    plt.text(11, -6.5, tst_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"D\",fontsize=20,fontweight='bold')\n",
    "\n",
    "    sub5 = plt.subplot(5, 2, 5)\n",
    "    plt.plot(train3,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_train3,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TRAIN\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.ylim(-7,2)\n",
    "    trn_rmse=\"RMSE: \"+str(format(error_train3,'.2f'))\n",
    "    plt.text(45, -6.5, trn_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"E\",fontsize=20,fontweight='bold')\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    sub6 = plt.subplot(5, 2, 6)\n",
    "    # sub2.set_yticks([1,0,-1,-2,-3,-4,-5,-6])\n",
    "    plt.plot(test3,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_test3,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TEST\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    plt.ylim(-7,2)\n",
    "    # place a text box in lower right in axes coords\n",
    "    tst_rmse=\"RMSE: \"+str(format(error_test3,'.2f'))\n",
    "    plt.text(11, -6.5, tst_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"F\",fontsize=20,fontweight='bold')\n",
    "\n",
    "    sub7 = plt.subplot(5, 2, 7)\n",
    "    plt.plot(train4,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_train4,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TRAIN\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.ylim(-7,2)\n",
    "    trn_rmse=\"RMSE: \"+str(format(error_train4,'.2f'))\n",
    "    plt.text(45, -6.5, trn_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"G\",fontsize=20,fontweight='bold')\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    sub8 = plt.subplot(5, 2, 8)\n",
    "    # sub2.set_yticks([1,0,-1,-2,-3,-4,-5,-6])\n",
    "    plt.plot(test4,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_test4,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TEST\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    plt.ylim(-7,2)\n",
    "    # place a text box in lower right in axes coords\n",
    "    tst_rmse=\"RMSE: \"+str(format(error_test4,'.2f'))\n",
    "    plt.text(11, -6.5, tst_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"H\",fontsize=20,fontweight='bold')\n",
    "\n",
    "    sub9 = plt.subplot(5, 2, 9)\n",
    "    plt.plot(train5,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_train5,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TRAIN\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.ylim(-7,2)\n",
    "    trn_rmse=\"RMSE: \"+str(format(error_train5,'.2f'))\n",
    "    plt.text(45, -6.5, trn_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"I\",fontsize=20,fontweight='bold')\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    sub10 = plt.subplot(5, 2, 10)\n",
    "    # sub2.set_yticks([1,0,-1,-2,-3,-4,-5,-6])\n",
    "    plt.plot(test5,color='orange',linewidth=2,label='Actual Data')\n",
    "    plt.plot(predictions_test5,'y--',color='black',linewidth=1,label='Predicted Data')\n",
    "    plt.legend(loc=2, prop={'size': 20})\n",
    "    # plt.title(\"SARIMA TEST\",fontsize=16)\n",
    "    plt.xlabel(\"Weeks\",fontsize=20)\n",
    "    plt.ylabel(\"Angle [\"+degree_sign+\"]\",fontsize=20)\n",
    "    plt.axhline(y=0, color='gray', linestyle='-',linewidth=1)\n",
    "    plt.legend(loc=3,framealpha=0)\n",
    "    plt.ylim(-7,2)\n",
    "    # place a text box in lower right in axes coords\n",
    "    tst_rmse=\"RMSE: \"+str(format(error_test5,'.2f'))\n",
    "    plt.text(11, -6.5, tst_rmse,fontsize=12,fontweight='bold')\n",
    "    plt.text(0, 1, \"J\",fontsize=20,fontweight='bold')\n",
    "\n",
    "    plt.savefig(\"SARIMABH.svg\",bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def sarima_test(data, n_test, cfg):\n",
    "    \n",
    "    predictions_test = list()\n",
    "    predictions_train = list()\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    \n",
    "    for i in range(6):\n",
    "        predictions_train.append(train[i])\n",
    "        \n",
    "    history_train = [x for x in train]\n",
    "    history_test = [x for x in train[:6]]\n",
    "    \n",
    "    for i in range(len(test)):\n",
    "        yhat = sarima_forecast(history_train, cfg)\n",
    "        predictions_test.append(yhat)\n",
    "        history_train.append(test[i])\n",
    "        \n",
    "    error_test = measure_rmse(test, predictions_test)\n",
    "\n",
    "    \n",
    "    for i in range(6,62):\n",
    "        yhat = sarima_forecast(history_test, cfg)\n",
    "        predictions_train.append(yhat)\n",
    "        history_test.append(train[i])\n",
    "        \n",
    "    error_train = measure_rmse(train, predictions_train)\n",
    "\n",
    "    \n",
    "    return predictions_train, predictions_test, error_train, error_test\n",
    "\n",
    "\n",
    "\n",
    "def find(data1,data2,data3,data4,data5, n_test, cfg):\n",
    "    \n",
    "    try:\n",
    "        # never show warnings when grid searching, too noisy\n",
    "        with catch_warnings():\n",
    "            filterwarnings(\"ignore\")\n",
    "#             predictions_train1, predictions_test1, error_train1, error_test1=sarima_test(data1, n_test, [(0, 1, 0), (0, 0, 1, 0), 'n'])\n",
    "#             predictions_train2, predictions_test2, error_train2, error_test2=sarima_test(data2, n_test, [(0, 0, 1), (1, 0, 1, 1), 'c'])\n",
    "#             predictions_train3, predictions_test3, error_train3, error_test3=sarima_test(data3, n_test, [(0, 1, 1), (0, 0, 0, 0), 'n'])\n",
    "#             predictions_train4, predictions_test4, error_train4, error_test4=sarima_test(data4, n_test, [(2, 0, 1), (0, 0, 1, 0), 'n'])\n",
    "#             predictions_train5, predictions_test5, error_train5, error_test5=sarima_test(data5, n_test, [(1, 0, 0), (0, 0, 0, 0), 'n'])\n",
    "            predictions_train1, predictions_test1, error_train1, error_test1=sarima_test(data1, n_test, cfg)\n",
    "            predictions_train2, predictions_test2, error_train2, error_test2=sarima_test(data2, n_test, cfg)\n",
    "            predictions_train3, predictions_test3, error_train3, error_test3=sarima_test(data3, n_test, cfg)\n",
    "            predictions_train4, predictions_test4, error_train4, error_test4=sarima_test(data4, n_test, cfg)\n",
    "            predictions_train5, predictions_test5, error_train5, error_test5=sarima_test(data5, n_test, cfg)\n",
    "            avg_train=(error_train1+error_train2+error_train3+error_train4+error_train5)/5\n",
    "            avg_test=(error_test1+error_test2+error_test3+error_test4+error_test5)/5\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return predictions_train1,predictions_train2,predictions_train3,predictions_train4,predictions_train5,predictions_test1,predictions_test2,predictions_test3,predictions_test4,predictions_test5,error_train1,error_train2,error_train3,error_train4,error_train5,error_test1,error_test2,error_test3,error_test4,error_test5,avg_train,avg_test\n",
    "\n",
    "def best_model(data1,data2,data3,data4,data5,scores):\n",
    "    # data split\n",
    "    n_test = 16\n",
    "\n",
    "    cfg=scores[0][0]\n",
    "\n",
    "\n",
    "    train1,test1=train_test_split(data1, n_test)\n",
    "    train2,test2=train_test_split(data2, n_test)\n",
    "    train3,test3=train_test_split(data3, n_test)\n",
    "    train4,test4=train_test_split(data4, n_test)\n",
    "    train5,test5=train_test_split(data5, n_test)\n",
    "\n",
    "    predictions_train1,predictions_train2,predictions_train3,predictions_train4,predictions_train5,predictions_test1,predictions_test2,predictions_test3,predictions_test4,predictions_test5,error_train1,error_train2,error_train3,error_train4,error_train5,error_test1,error_test2,error_test3,error_test4,error_test5,avg_train,avg_test = find(data1,data2,data3,data4,data5, n_test, cfg)\n",
    "\n",
    "    print('________________________________________________________________________________________________')\n",
    "    print('| BH1\\t| BH1\\t| BH2\\t| BH2\\t| BH3\\t| BH3\\t| BH4\\t| BH4\\t| BH5\\t| BH5\\t| Train\\t| Test |')\n",
    "    print('________________________________________________________________________________________________')\n",
    "    print( '|%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f  |%.3f |' % (error_train1,error_test1,error_train2,error_test2,error_train3,error_test3,error_train4,error_test4,error_train5,error_test5,avg_train,avg_test))\n",
    "    print('________________________________________________________________________________________________')\n",
    "#     print('__________________________________Train 1_______________________________________________________')\n",
    "#     print(predictions_train1)\n",
    "#     print('__________________________________Test 1 _______________________________________________________')\n",
    "#     print(predictions_test1)\n",
    "#     print('__________________________________Train 2_______________________________________________________')\n",
    "#     print(predictions_train2)\n",
    "#     print('__________________________________Test 2 _______________________________________________________')\n",
    "#     print(predictions_test2)\n",
    "#     print('__________________________________Train 3_______________________________________________________')\n",
    "#     print(predictions_train3)\n",
    "#     print('__________________________________Test 3 _______________________________________________________')\n",
    "#     print(predictions_test3)\n",
    "#     print('__________________________________Train 4_______________________________________________________')\n",
    "#     print(predictions_train4)\n",
    "#     print('__________________________________Test 4 _______________________________________________________')\n",
    "#     print(predictions_test4)\n",
    "#     print('__________________________________Train 5_______________________________________________________')\n",
    "#     print(predictions_train5)\n",
    "#     print('__________________________________Test 5 _______________________________________________________')\n",
    "#     print(predictions_test5)\n",
    "    figure(train1,test1,train2,test2,train3,test3,train4,test4,train5,test5,predictions_train1,predictions_train2,predictions_train3,predictions_train4,predictions_train5,predictions_test1,predictions_test2,predictions_test3,predictions_test4,predictions_test5,error_train1,error_train2,error_train3,error_train4,error_train5,error_test1,error_test2,error_test3,error_test4,error_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9cdc4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TEST_TRAIN_DATA = 'Tangni/Data/'\n",
    "\n",
    "#### define dataset\n",
    "series1 = read_csv(PATH_TO_TEST_TRAIN_DATA + '1-3.csv', header=0, usecols=[0,1], index_col=0) \n",
    "data1 = series1.values\n",
    "\n",
    "series2 = read_csv(PATH_TO_TEST_TRAIN_DATA + '2-12.csv', header=0, usecols=[0,1], index_col=0) \n",
    "data2 = series2.values\n",
    "\n",
    "series3 = read_csv(PATH_TO_TEST_TRAIN_DATA + '3-6.csv', header=0, usecols=[0,1], index_col=0) \n",
    "data3 = series3.values\n",
    "\n",
    "series4 = read_csv(PATH_TO_TEST_TRAIN_DATA + '4-15.csv', header=0, usecols=[0,1], index_col=0) \n",
    "data4 = series4.values\n",
    "\n",
    "series5 = read_csv(PATH_TO_TEST_TRAIN_DATA + '5-15.csv', header=0, usecols=[0,1], index_col=0) \n",
    "data5 = series5.values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f43bb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdd5d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f96a2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarima_configs(seasonal=[0]):\n",
    "    models = list()\n",
    "    count=0\n",
    "    # define config lists \n",
    "    p_params = [0,1,2,3,4,5]\n",
    "    d_params = [0,1,2,3,4,5]\n",
    "    q_params = [0,1,2,3,4,5]\n",
    "    t_params = ['n','c','t','ct']\n",
    "    P_params = [0,1,2,3,4,5]\n",
    "    D_params = [0,1,2,3,4,5]\n",
    "    Q_params = [0,1,2,3,4,5]\n",
    "    m_params = [0,1,2,3,4,5]\n",
    "    # create config instances\n",
    "    for p in p_params:\n",
    "        for d in d_params:\n",
    "            for q in q_params:\n",
    "                for t in t_params:\n",
    "                    for P in P_params:\n",
    "                        for D in D_params:\n",
    "                            for Q in Q_params:\n",
    "                                for m in m_params:\n",
    "                                    cfg = [(p,d,q), (P,D,Q,m), t]\n",
    "                                    models.append(cfg)\n",
    "                                    count=count+1\n",
    "    \n",
    "    return models,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c75d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d798e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 0, 0), 'n']] [2.94396]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 0, 5), 'n']] [2.94396]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 0, 2), 'n']] [2.94396]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 0, 4), 'n']] [2.94396]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 1, 2), 'n']] [2.03216]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 0, 3), 'n']] [2.94396]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 2, 0, 2), 'n']] [0.71278]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 1, 0, 4), 'n']] [0.72906]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 1, 0, 3), 'n']] [0.68087][1/1119744]> Model[[(0, 0, 0), (0, 1, 0, 2), 'n']] [0.51976]\n",
      "\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 1, 0, 5), 'n']] [0.72540]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 1, 3), 'n']] [2.29474]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 2, 0, 4), 'n']] [1.07040]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 1, 1, 2), 'n']] [0.50298]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 2, 0, 5), 'n']] [0.93452]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 2, 0, 3), 'n']] [0.92985]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 2, 1, 2), 'n']] [0.57560]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 1, 5), 'n']] [2.35766]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 1, 1, 3), 'n']] [0.66197]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 1, 4), 'n']] [2.38213]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 1, 1, 4), 'n']] [0.71516]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 1, 1, 5), 'n']] [0.73323]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 1, 2, 2), 'n']] [0.54654]\n",
      "[2/1119744]> Model[[(0, 0, 0), (0, 2, 1, 3), 'n']] [0.70295]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 2, 2), 'n']] [1.70726]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 2, 3), 'n']] [1.81925]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 3, 0, 2), 'n']] [0.99804]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 2, 1, 4), 'n']] [0.79168]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 1, 2, 3), 'n']] [0.65739]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 2, 1, 5), 'n']] [0.81253]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 1, 2, 5), 'n']] [0.68811]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 1, 3, 2), 'n']] [0.57798]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 2, 4), 'n']] [2.04763]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 1, 2, 4), 'n']] [0.76424]\n",
      "[2/1119744]> Model[[(0, 0, 0), (0, 3, 0, 3), 'n']] [1.56731]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 2, 5), 'n']] [1.98517]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 1, 3, 3), 'n']] [0.60770]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 3, 2), 'n']] [1.35872]\n",
      "[2/1119744]> Model[[(0, 0, 0), (0, 3, 0, 4), 'n']] [1.59034]\n",
      "[2/1119744]> Model[[(0, 0, 0), (0, 2, 2, 2), 'n']] [0.62651]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 3, 3), 'n']] [1.49342]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 2, 2, 3), 'n']] [0.72948]\n",
      "[2/1119744]> Model[[(0, 0, 0), (0, 3, 1, 2), 'n']] [0.73979]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 4, 2), 'n']] [1.18752]\n",
      "[2/1119744]> Model[[(0, 0, 0), (0, 4, 0, 2), 'n']] [1.02328]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 1, 5, 2), 'n']] [0.65074]\n",
      "[2/1119744]> Model[[(0, 0, 0), (0, 3, 0, 5), 'n']] [1.44214]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 2, 3, 2), 'n']] [0.67974]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 1, 4, 2), 'n']] [0.63484]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 4, 3), 'n']] [1.40306]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 3, 4), 'n']] [1.61240]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 5, 2), 'n']] [1.10888]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 3, 2, 2), 'n']] [0.75220]\n",
      "[2/1119744]> Model[[(0, 0, 0), (0, 4, 0, 3), 'n']] [1.35988]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 3, 5), 'n']] [2.01111]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 1, 4, 3), 'n']] [0.60332]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 2, 3, 3), 'n']] [0.77677]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 5, 0, 2), 'n']] [1.26092]\n",
      "[2/1119744]> Model[[(0, 0, 0), (0, 3, 1, 3), 'n']] [1.00081]\n",
      "[2/1119744]> Model[[(0, 0, 0), (0, 4, 1, 2), 'n']] [0.77499]\n",
      "[2/1119744]> Model[[(0, 0, 0), (0, 5, 0, 3), 'n']] [1.47437]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 2, 4, 2), 'n']] [0.74615]\n",
      "[2/1119744]> Model[[(0, 0, 0), (0, 3, 3, 2), 'n']] [0.76379]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 0, 5, 3), 'n']] [1.47209]\n",
      "[1/1119744]> Model[[(0, 0, 0), (0, 5, 1, 2), 'n']] [1.25103]\n",
      "[2/1119744]> Model[[(0, 0, 0), (0, 4, 2, 2), 'n']] [0.79277]\n"
     ]
    }
   ],
   "source": [
    "scores=find_best_models(data1,data2,data3,data4,data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03665829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 0), (0, 0, 0, 0), 'n']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "745ec6c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2812234/1464777158.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "scores[0][0] = [(1, 1, 0), (0, 0, 0, 0), 'n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e729b683",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2812234/425142488.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2812234/4136833598.py\u001b[0m in \u001b[0;36mbest_model\u001b[0;34m(data1, data2, data3, data4, data5, scores)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mtrain5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0mpredictions_train1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions_train2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions_train3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions_train4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions_train5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions_test1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions_test2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions_test3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions_test4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions_test5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_train1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_train2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_train3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_train4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_train5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_test1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_test2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_test3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_test4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_test5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavg_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavg_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'________________________________________________________________________________________________'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "best_model(data1,data2,data3,data4,data5,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "043340b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 1), (0, 0, 0, 0), 'n']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(0, 1, 1), (0, 0, 0, 0), 'n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2150593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
